= Advent of Code 2025
:doctype: book
:toc: macro
:sectnums:

image:https://godoc.org/gitlab.com/jhinrichsen/adventofcode2025?status.svg["godoc", link="https://godoc.org/gitlab.com/jhinrichsen/adventofcode2025"]
image:https://goreportcard.com/badge/gitlab.com/jhinrichsen/adventofcode2025["Go report card", link="https://goreportcard.com/report/gitlab.com/jhinrichsen/adventofcode2025"]
image:https://gitlab.com/jhinrichsen/adventofcode2025/badges/main/pipeline.svg[link="https://gitlab.com/jhinrichsen/adventofcode2025/-/commits/main",title="pipeline status"]
image:https://gitlab.com/jhinrichsen/adventofcode2025/badges/main/coverage.svg[link="https://gitlab.com/jhinrichsen/adventofcode2025/-/commits/main",title="coverage report"]
image:https://img.shields.io/badge/runtime-tbd-brightgreen.svg["runtime: tbd"]

toc::[]

My take on https://adventofcode.com/2025/ in Go.
As usual, i don't particularly care if i provide my solutions _fast_, i try to be _correct_ on the first answer, and care for being runtime efficient.
The goal is to be subsecond for all puzzles - all puzzles sequentially under one second, not each puzzle. Aim high.

Answers are hard coded into the unit tests, so avoid looking at `_test.go` files.

== Number of tries

|===
| Day | Part 1 | Part 2
| 1   |        |
| 2   |        |
| 3   |        |
| 4   |        |
| 5   |        |
| 6   |        |
| 7   |        |
| 8   |        |
| 9   |        |
| 10  |        |
| 11  |        |
| 12  |        |
| 13  |        |
| 14  |        |
| 15  |        |
| 16  |        |
| 17  |        |
| 18  |        |
| 19  |        |
| 20  |        |
| 21  |        |
| 22  |        |
| 23  |        |
| 24  |        |
| 25  |        |
|===

== Day 1: Secret Entrance

=== Branch Prediction vs Branchless

The puzzle requires moving a dial position left or right. A standard implementation would branch on the direction:

	if direction == LEFT {
	    position = position - n
	} else {
	    position = position + n
	}

=== The Problem with Branches

Modern CPUs use speculative execution and pipelining.
When the CPU encounters an `if` statement, it must predict which path to take:

* Correct prediction cost: ~1-2 cycles
* Misprediction cost: ~10-20 cycles (pipeline flush and restart)

With unpredictable data (random L/R directions), the branch predictor guesses wrong frequently, causing pipeline stalls.

NOTE: The Linux kernel provides `likely()`/`unlikely()` to hint which branch is more probable.
Go does not provide branch hint mechanisms.

	if (likely(happy_path)) {
		...
	}


This helps the compiler optimize instruction layout for the common case.
However, in our puzzle the L/R directions are unpredictable - there's no "likely" path.
With random data, branch hints don't help and mispredictions remain costly.

=== The Branchless Alternative

To unify these operations, we can extract a sign (-1/+1) and use multiplication: `position = position + sign * n`.
This approach has no branches, allowing consistent pipelining regardless of input data.

On modern CPUs, the branchless multiplication approach is typically *faster* in unpredictable scenarios.

=== Branchless is Predictable

* `value * sign` has no branches
* Allows consistent pipelining
* No dependence on branch predictor

=== Multiplication Speed

Modern CPUs have fast integer multipliers:

* Integer multiplication: 1-3 cycles latency on modern x86/ARM
* Nearly as fast as addition/subtraction

=== Performance Comparison

	// Branch approach
	if (sign >= 0) {
	    result = a + b
	} else {
	    result = a - b
	}
	// Cost: 1 cycle if predicted correctly, 10-20 if mispredicted

	// Branchless approach
	result = a + (b * sign);  // where sign is +1 or -1
	// Cost: ~3 cycles consistently

For branchless to work, we also need a branchless sign, so

	if n < 0 {
		sign = -1
	}

is not an option.

=== The Bit Trick: Extracting Sign from 'L' and 'R'

This exploits the ASCII encoding of 'L' and 'R':

* `'L'` = 0x4C = 0b010011**0**0 (ASCII 76)
* `'R'` = 0x52 = 0b010100**1**0 (ASCII 82)

Notice that bit position 2 (the `2` bit, or `0b00000010`) differs between them:

* `'L' & 0b00000010` = 0b01001100 & 0b00000000 = 0
* `'R' & 0b00000010` = 0b01010010 & 0b00000010 = 2

After subtracting 1, we get our sign:

* L: `0 - 1 = -1` (left direction)
* R: `2 - 1 = +1` (right direction)

This requires only two CPU operations (AND + SUB) with no branches, making it extremely efficient and predictable.

Assembler listing for amd64

----
MOVBLZX (AX)(CX*1), R8       # Load direction directly from puzzle input into R8
ANDL    $2, R8               # Extract bit 2
LEAQ    -1(R8), SI           # Subtract 1
----

In comparison, ARM AArch64

----
MOVBU   (R0)(R2), R6         # Load direction directly from puzzle input into R6
AND     $2, R6, R6           # Extract bit 2
SUB     $1, R6, R6           # Subtract 1
----

=== Implementation Notes for Part 1

The optimized `Day01()` function showcases several performance techniques:

* *No imports*: All logic is implemented using only compiler built-in operations (arithmetic, bitwise, etc.)
* *No heap allocation*: Zero GC pressure - only stack-allocated variables
* *Branchless direction extraction*: Uses bit manipulation (`direction & 2) - 1`) to convert 'L'/'R' to -1/+1 without conditionals
* *Minimal branches*: Only 2 for loops for iteration
* *Branchless wraparound*: Double modulo `((dial+sign*n)%RANGE + RANGE) % RANGE` handles both directions

Interestingly, the branchless direction extraction is ~ 2.5% slower than the branched version despite using only one AND and one SUB operation, likely due to the highly predictable nature of the branch predictor on this input.

== Benchmarks

NOTE: work in progress until end of AOC

The total runtime to run each the benchmark for each day (1..25), part 1 and 2 (except for day 25, which does not have a part 2) is

	to be determined...

== SAST (Static Application Security Testing)

This project uses custom SAST tooling in GitLab CI, optimized for the free tier.

=== GitLab Free Tier Limitations

GitLab's built-in SAST features (Security Dashboard, vulnerability management, merge request security widgets) require the Ultimate tier. On the free tier, SAST scans can run but results are only available as downloadable JSON artifacts.

=== Current Setup

Our CI pipeline uses:

- Code Quality Reports: golangci-lint → JSON → banyansecurity/golint-convert → CodeClimate JSON format
  * Displays findings in merge request Code Quality widget (available in free tier since GitLab 13.2)
  * Shows code quality degradations/improvements directly in MRs

- Test Reports: go-junit-report/v2 → JUnit XML format
  * Integrates test results into GitLab's test report UI

- Coverage Reports: gocover-cobertura → Cobertura XML format
  * Shows coverage metrics and trends in merge requests

- Vulnerability Scanning: govulncheck (periodic, scheduled pipeline)
  * Scans for known vulnerabilities in Go dependencies
  * Runs on a schedule to catch newly disclosed vulnerabilities
  * Results available as JSON artifacts (no UI on free tier)

=== Note on Deprecation

GitLab deprecated its built-in CodeClimate scanning template in version 17.3 (planned removal in 19.0). This only affects GitLab's bundled scanning engine. Custom pipelines that generate CodeClimate-format JSON (like ours) continue to work and are the recommended approach for free tier users.

The Code Quality widget will continue to display results from custom CodeClimate JSON reports.
